{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nSFB7fLLzA-b"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/yesno_zoomasr_model.zip /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/yesno_zoomasr_model.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-48HmrzVzuYD",
        "outputId": "80146e4d-3e0d-42c4-eb41-a0cf3fc55c18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/yesno_zoomasr_model.zip\n",
            "   creating: content/model/\n",
            " extracting: content/model/tokenizer_vocab.txt  \n",
            "   creating: content/model/zoomasr/\n",
            " extracting: content/model/zoomasr/fingerprint.pb  \n",
            "   creating: content/model/zoomasr/variables/\n",
            "  inflating: content/model/zoomasr/variables/variables.data-00000-of-00001  \n",
            "  inflating: content/model/zoomasr/variables/variables.index  \n",
            "  inflating: content/model/zoomasr/saved_model.pb  \n",
            "  inflating: content/model/zoomasr/keras_metadata.pb  \n",
            "   creating: content/model/zoomasr/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWhZmTGD0DuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kYWNpyvU0Dr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the tokenizer vocabulary from the JSON file\n",
        "with open(\"content/model/tokenizer_vocab.txt\", \"r\") as file:\n",
        "    idx_to_char = file.read()\n",
        "\n",
        "characters = [x for x in idx_to_char]\n",
        "# Mapping characters to integers\n",
        "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "# An integer scalar Tensor. The window length in samples.\n",
        "frame_length = 256\n",
        "# An integer scalar Tensor. The number of samples to step.\n",
        "frame_step = 160\n",
        "# An integer scalar Tensor. The size of the FFT to apply.\n",
        "# If not provided, uses the smallest power of 2 enclosing frame_length.\n",
        "fft_length = 384\n",
        "\n",
        "\n",
        "def encode_aud(wav_file):\n",
        "    \"\"\"\n",
        "    audio file encoder\n",
        "    params : wav audio file path\n",
        "    return : spectogram\n",
        "     \"\"\"\n",
        "    file = tf.io.read_file(wav_file)\n",
        "    audio, _ = tf.audio.decode_wav(file)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "    spectrogram = tf.signal.stft(\n",
        "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
        "    )\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
        "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(result)\n",
        "    return output_text\n",
        "\n",
        "\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    # Compute the training-time loss value\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with keras.utils.custom_object_scope({'CTCLoss': CTCLoss}):\n",
        "    loaded_model = tf.keras.models.load_model(\"content/model/zoomasr\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zb0KVZpzbec",
        "outputId": "3831ec0d-ac89-44f7-b7bb-c5c3f44f1000"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary is: ['', '<', 'U', 'N', 'K', '>', 'ැ', ' ', 'ඔ', 'ව', '්', 'න', 'හ'] (size =13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#############################################################\n",
        "################### Give Audio Path And Run #################\n",
        "#############################################################\n",
        "\n",
        "aud = \"/content/0_0_1_0_0_0_1_0.wav\"\n",
        "\n",
        "#############################################################\n",
        "\n",
        "\n",
        "aud = encode_aud(aud)\n",
        "aud = tf.expand_dims(aud, axis=0)\n",
        "#Make preds by ai\n",
        "pred = loaded_model.predict(aud)\n",
        "#decode and detokenize it\n",
        "pred = decode_batch_predictions(pred)\n",
        "print(pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXaj4AuFzipI",
        "outputId": "94c15cf7-43f9-4b45-a30e-c3b1f2d29b5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "['නැහැ නැහැ ඔව් නැහැ නැහැ නැහැ ඔව් නැහැ']\n"
          ]
        }
      ]
    }
  ]
}